#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Storyboard Processor

å¤„ç† storyboard.json æ–‡ä»¶ï¼Œç”Ÿæˆä¸‰ä¸ªè¾“å‡ºï¼š
1. enhanced_flux_image_prompts.json: LLMç›´æ¥ç”Ÿæˆçš„é«˜è´¨é‡å›¾åƒprompts
2. storyline.json: æ•…äº‹çº¿å†…å®¹çš„JSONæ•°ç»„
3. ä½¿ç”¨Azure AI Speech Serviceç”Ÿæˆstorylineçš„é…éŸ³æ–‡ä»¶ï¼ˆé»˜è®¤å¯ç”¨ï¼‰

Usage:
    python storyboard_processor.py [--shot shot_name] [--no-audio] [--no-enhance] [--assets-dir path]

Examples:
    python storyboard_processor.py                              # å¤„ç†æ‰€æœ‰æ•…äº‹æ¿ï¼Œè‡ªåŠ¨ç”ŸæˆéŸ³é¢‘å’ŒLLM prompts
    python storyboard_processor.py --shot shot_01               # å¤„ç†æŒ‡å®šæ•…äº‹æ¿ï¼Œè‡ªåŠ¨ç”ŸæˆéŸ³é¢‘å’ŒLLM prompts
    python storyboard_processor.py --no-audio                   # è·³è¿‡éŸ³é¢‘ç”Ÿæˆ
    python storyboard_processor.py --no-enhance                 # è·³è¿‡LLMç”Ÿæˆï¼Œä½¿ç”¨åŸºç¡€ç¿»è¯‘
    python storyboard_processor.py --shot shot_01 --no-audio --no-enhance  # åªå¤„ç†åŸºç¡€promptså’Œå­—å¹•
"""

import json
import os
import sys
import argparse
from pathlib import Path
from typing import Dict, List, Any, Tuple
from dotenv import load_dotenv
import re
from datetime import datetime

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# Azure AI Speech Service è¯­éŸ³åˆæˆå·¥å…·
try:
    import azure.cognitiveservices.speech as speechsdk
    AZURE_SPEECH_AVAILABLE = True
except ImportError:
    AZURE_SPEECH_AVAILABLE = False
    print("è­¦å‘Š: azure-cognitiveservices-speech æœªå®‰è£…ï¼Œè¯­éŸ³åˆæˆåŠŸèƒ½å°†ä¸å¯ç”¨")

# OpenAI LLM API for prompt enhancement
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("è­¦å‘Š: openai æœªå®‰è£…ï¼Œpromptå¢å¼ºåŠŸèƒ½å°†ä¸å¯ç”¨")

from enum import Enum

class VoiceType(Enum):
    """æ”¯æŒçš„ä¸­æ–‡éŸ³è‰²æšä¸¾"""
    YUNXI = "zh-CN-YunxiNeural"      # å¹´è½»ç”·æ€§ï¼Œæ¸©å’Œå‹å¥½
    YUNYE = "zh-CN-YunyeNeural"      # æˆç†Ÿç”·æ€§ï¼Œç¨³é‡ä¸“ä¸š  
    XIAOXIAO = "zh-CN-XiaoxiaoNeural" # ç”œç¾å¥³æ€§ï¼Œæ´»æ³¼å¯çˆ±

class AzureSpeechSynthesizer:
    """Azureè¯­éŸ³åˆæˆå™¨ç±»"""
    
    def __init__(self, speech_key: str, region: str):
        """åˆå§‹åŒ–è¯­éŸ³åˆæˆå™¨
        
        Args:
            speech_key: Azure Speech Serviceå¯†é’¥
            region: æœåŠ¡åŒºåŸŸ
        """
        if not AZURE_SPEECH_AVAILABLE:
            raise ImportError("azure-cognitiveservices-speech æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install azure-cognitiveservices-speech")
            
        self.speech_key = speech_key
        self.region = region
        self.base_config = speechsdk.SpeechConfig(subscription=speech_key, region=region)
        self.base_config.speech_synthesis_language = "zh-CN"
    
    def synthesize_text(self, text: str, voice: VoiceType, output_file: str = None) -> bytes:
        """åˆæˆæ–‡æœ¬ä¸ºè¯­éŸ³
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            voice: éŸ³è‰²ç±»å‹ (VoiceTypeæšä¸¾)
            output_file: è¾“å‡ºæ–‡ä»¶åï¼Œå¦‚æœä¸ºNoneåˆ™ä¸ä¿å­˜æ–‡ä»¶
            
        Returns:
            bytes: éŸ³é¢‘æ•°æ®
            
        Raises:
            Exception: åˆæˆå¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        # åˆ›å»ºè¯­éŸ³é…ç½®
        config = speechsdk.SpeechConfig(subscription=self.speech_key, region=self.region)
        config.speech_synthesis_language = "zh-CN"
        config.speech_synthesis_voice_name = voice.value
        
        # åˆ›å»ºåˆæˆå™¨ï¼ˆä¸è®¾ç½®éŸ³é¢‘è¾“å‡ºè®¾å¤‡ï¼Œåªç”ŸæˆéŸ³é¢‘æ•°æ®ï¼‰
        synthesizer = speechsdk.SpeechSynthesizer(speech_config=config, audio_config=None)
        
        # åˆæˆè¯­éŸ³
        result = synthesizer.speak_text_async(text).get()
        
        # æ£€æŸ¥ç»“æœ
        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
            # ä¿å­˜æ–‡ä»¶ï¼ˆå¦‚æœæŒ‡å®šäº†è¾“å‡ºæ–‡ä»¶ï¼‰
            if output_file:
                with open(output_file, "wb") as f:
                    f.write(result.audio_data)
            
            return result.audio_data
            
        elif result.reason == speechsdk.ResultReason.Canceled:
            cancellation_details = result.cancellation_details
            error_msg = f"è¯­éŸ³åˆæˆå¤±è´¥: {cancellation_details.reason}"
            if cancellation_details.reason == speechsdk.CancellationReason.Error:
                error_msg += f"\né”™è¯¯è¯¦æƒ…: {cancellation_details.error_details}"
            raise Exception(error_msg)
        else:
            raise Exception(f"æœªçŸ¥é”™è¯¯: {result.reason}")


class PromptEnhancer:
    """ä½¿ç”¨LLMå¢å¼ºFluxå›¾åƒç”Ÿæˆpromptçš„ç±»"""
    
    def __init__(self, api_key: str = None):
        """
        åˆå§‹åŒ–promptå¢å¼ºå™¨
        
        Args:
            api_key: ARK APIå¯†é’¥ï¼Œå¦‚æœä¸ºNoneåˆ™ä»ç¯å¢ƒå˜é‡ARK_API_KEYè¯»å–
        """
        if not OPENAI_AVAILABLE:
            raise ImportError("openai æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install --upgrade \"openai>=1.0\"")
        
        self.api_key = api_key or os.getenv('ARK_API_KEY')
        if not self.api_key:
            raise ValueError("æœªæ‰¾åˆ° ARK_API_KEYï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­æ·»åŠ : ARK_API_KEY=your_api_key_here")
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        self.client = OpenAI(
            base_url="https://ark.cn-beijing.volces.com/api/v3",
            api_key=self.api_key,
        )
    
    def enhance_flux_prompts_batch(self, visual_descriptions: List[Dict[str, str]]) -> List[Dict[str, str]]:
        """
        ä½¿ç”¨LLMåŸºäºä¸­æ–‡æè¿°ç›´æ¥ç”Ÿæˆé«˜è´¨é‡çš„Fluxå›¾åƒç”Ÿæˆprompts
        
        Args:
            visual_descriptions: åŒ…å«ä¸­æ–‡æè¿°çš„è§†è§‰æè¿°åˆ—è¡¨
            
        Returns:
            List[Dict[str, str]]: ç”Ÿæˆå®Œæ•´Flux promptsçš„è§†è§‰æè¿°åˆ—è¡¨
        """
        try:
            # æ„å»ºç³»ç»Ÿprompt
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIå›¾åƒç”Ÿæˆpromptä¸“å®¶ï¼Œä¸“é—¨ä¸ºFlux AIå›¾åƒç”Ÿæˆæ¨¡å‹åˆ›å»ºé«˜è´¨é‡çš„è‹±æ–‡promptã€‚

ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç»™å®šçš„ä¸­æ–‡è§†è§‰æè¿°ï¼Œç›´æ¥ç”Ÿæˆä¸“ä¸šçš„è‹±æ–‡Flux promptï¼Œè¦æ±‚ï¼š
1. è¯¦ç»†å‡†ç¡®åœ°æè¿°ç”»é¢å†…å®¹
2. åŒ…å«ä¸“ä¸šçš„è‰ºæœ¯é£æ ¼æè¿°
3. æ·»åŠ é€‚å½“çš„å…‰å½±æ•ˆæœæè¿°
4. å¢å¼ºç”»é¢æ„å›¾å’Œè§†è§‰æ•ˆæœ
5. ä¿æŒåœºæ™¯ä¹‹é—´çš„è¿è´¯æ€§å’Œé£æ ¼ç»Ÿä¸€æ€§
6. ä½¿ç”¨ä¸“ä¸šçš„è‹±æ–‡è‰ºæœ¯æœ¯è¯­

è¯·è¿”å›ç›¸åŒJSONæ ¼å¼ï¼Œä¸ºæ¯ä¸ªåœºæ™¯æ·»åŠ flux_promptå­—æ®µï¼Œä¿æŒå…¶ä»–å­—æ®µä¸å˜ã€‚
ç”Ÿæˆçš„promptåº”è¯¥é€‚åˆFlux AIå›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œé£æ ¼ç»Ÿä¸€ã€è¯¦ç»†ä¸“ä¸šã€‚"""

            # å°†visual_descriptionsè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
            input_json = json.dumps(visual_descriptions, ensure_ascii=False, indent=2)
            
            # æ„å»ºç”¨æˆ·prompt
            user_content = f"""è¯·æ ¹æ®ä»¥ä¸‹JSONä¸­æ¯ä¸ªåœºæ™¯çš„chinese_descriptionï¼Œç”Ÿæˆå¯¹åº”çš„flux_promptå­—æ®µï¼Œä¿æŒJSONæ ¼å¼ä¸å˜ï¼š

{input_json}

è¦æ±‚ï¼š
1. ä¸ºæ¯ä¸ªåœºæ™¯æ·»åŠ flux_promptå­—æ®µï¼ˆåŸºäºchinese_descriptionç”Ÿæˆï¼‰
2. ä¿æŒscene_numberå’Œchinese_descriptionå­—æ®µä¸å˜
3. ç¡®ä¿æ‰€æœ‰åœºæ™¯çš„é£æ ¼ä¿æŒä¸€è‡´ï¼Œé€‚åˆè¿ç»­çš„è§†é¢‘åœºæ™¯
4. flux_promptè¦è¯¦ç»†ã€ä¸“ä¸šï¼Œé€‚åˆFlux AIå›¾åƒç”Ÿæˆ
5. åŒ…å«é€‚å½“çš„ç”»è´¨ã€å…‰å½±ã€æ„å›¾æè¿°
6. è¿”å›å®Œæ•´çš„JSONæ ¼å¼

ç¤ºä¾‹flux_promptæ ¼å¼ï¼š
"Cinematic shot, high quality, detailed rendering, [å…·ä½“åœºæ™¯æè¿°], dramatic lighting, masterpiece, best quality, ultra detailed, 8k resolution"
"""
            
            # è°ƒç”¨LLM API
            response = self.client.chat.completions.create(
                model="doubao-1-5-pro-32k-250115",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_content}
                ],
                temperature=0.7,
                max_tokens=8000  # å¢åŠ tokené™åˆ¶ä»¥å¤„ç†æ›´å¤šå†…å®¹
            )
            
            enhanced_content = response.choices[0].message.content.strip()
            
            # å°è¯•è§£æè¿”å›çš„JSON
            try:
                # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
                if enhanced_content.startswith("```json"):
                    enhanced_content = enhanced_content[7:]
                if enhanced_content.startswith("```"):
                    enhanced_content = enhanced_content[3:]
                if enhanced_content.endswith("```"):
                    enhanced_content = enhanced_content[:-3]
                
                enhanced_descriptions = json.loads(enhanced_content.strip())
                
                # éªŒè¯è¿”å›çš„æ•°æ®ç»“æ„
                if isinstance(enhanced_descriptions, list) and len(enhanced_descriptions) == len(visual_descriptions):
                    # éªŒè¯æ¯ä¸ªæè¿°éƒ½æœ‰flux_promptå­—æ®µ
                    for i, desc in enumerate(enhanced_descriptions):
                        if not desc.get('flux_prompt'):
                            print(f"âš ï¸  åœºæ™¯ {desc.get('scene_number', i+1)} çš„flux_promptä¸ºç©ºï¼Œç”Ÿæˆé»˜è®¤prompt")
                            chinese_desc = desc.get('chinese_description', '')
                            desc['flux_prompt'] = f"Cinematic shot, high quality, detailed rendering, {chinese_desc}, dramatic lighting, masterpiece, best quality, ultra detailed, 8k resolution"
                    
                    return enhanced_descriptions
                else:
                    print(f"âš ï¸  LLMè¿”å›çš„æ•°æ®ç»“æ„ä¸æ­£ç¡®")
                    return self._generate_fallback_prompts(visual_descriptions)
                    
            except json.JSONDecodeError as e:
                print(f"âš ï¸  LLMè¿”å›çš„å†…å®¹æ— æ³•è§£æä¸ºJSON: {e}")
                print(f"è¿”å›å†…å®¹: {enhanced_content[:500]}...")
                return self._generate_fallback_prompts(visual_descriptions)
            
        except Exception as e:
            print(f"âš ï¸  LLM promptç”Ÿæˆå¤±è´¥: {e}")
            return self._generate_fallback_prompts(visual_descriptions)
    
    def _generate_fallback_prompts(self, visual_descriptions: List[Dict[str, str]]) -> List[Dict[str, str]]:
        """
        ç”Ÿæˆå¤‡ç”¨çš„åŸºç¡€Flux prompts
        
        Args:
            visual_descriptions: ä¸­æ–‡è§†è§‰æè¿°åˆ—è¡¨
            
        Returns:
            æ·»åŠ äº†åŸºç¡€flux_promptçš„æè¿°åˆ—è¡¨
        """
        fallback_descriptions = []
        for desc in visual_descriptions:
            chinese_desc = desc.get('chinese_description', '')
            # ä½¿ç”¨åŸæœ‰çš„translate_to_flux_promptæ–¹æ³•ä½œä¸ºå¤‡ç”¨
            fallback_prompt = self.translate_to_flux_prompt(chinese_desc)
            
            fallback_desc = desc.copy()
            fallback_desc['flux_prompt'] = fallback_prompt
            fallback_descriptions.append(fallback_desc)
        
        return fallback_descriptions
    
    def generate_flux_prompts_batch(self, visual_descriptions: List[Dict[str, str]]) -> List[Dict[str, str]]:
        """
        ç”Ÿæˆvisual descriptionsä¸­çš„flux promptsï¼ˆç›´æ¥è°ƒç”¨LLMç”Ÿæˆæ–¹æ³•ï¼‰
        
        Args:
            visual_descriptions: åŒ…å«ä¸­æ–‡æè¿°çš„è§†è§‰æè¿°åˆ—è¡¨
            
        Returns:
            List[Dict[str, str]]: ç”Ÿæˆflux_promptåçš„è§†è§‰æè¿°åˆ—è¡¨
        """
        print(f"ğŸ¤– å¼€å§‹ä½¿ç”¨LLMç›´æ¥ç”Ÿæˆ {len(visual_descriptions)} ä¸ªå›¾åƒprompt...")
        
        enhanced_descriptions = self.enhance_flux_prompts_batch(visual_descriptions)
        
        if enhanced_descriptions == visual_descriptions:
            print(f"âš ï¸  LLMç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
        else:
            print(f"ğŸ¯ æ‰€æœ‰promptç”Ÿæˆå®Œæˆï¼")
        
        return enhanced_descriptions


class StoryboardProcessor:
    """æ•…äº‹æ¿å¤„ç†å™¨"""
    
    def __init__(self, shot_name: str = None, generate_audio: bool = True, storyboard_dir: str = "storyboard", assets_dir: str = "assets", enhance_prompts: bool = True):
        """
        åˆå§‹åŒ–å¤„ç†å™¨
        
        Args:
            shot_name: åˆ†é›†åç§°ï¼Œå¦‚ 'shot_01'ï¼Œå¦‚æœä¸ºNoneåˆ™å¤„ç†æ‰€æœ‰åˆ†é›†
            generate_audio: æ˜¯å¦ç”Ÿæˆé…éŸ³æ–‡ä»¶ï¼ˆé»˜è®¤ä¸ºTrueï¼‰
            storyboard_dir: storyboardæ–‡ä»¶ç›®å½•
            assets_dir: èµ„æºæ–‡ä»¶ç›®å½•
            enhance_prompts: æ˜¯å¦ä½¿ç”¨LLMå¢å¼ºå›¾åƒpromptsï¼ˆé»˜è®¤ä¸ºTrueï¼‰
        """
        self.shot_name = shot_name
        self.generate_audio = generate_audio
        self.enhance_prompts = enhance_prompts
        self.storyboard_dir = Path(storyboard_dir)
        self.assets_dir = Path(assets_dir)
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.assets_dir.mkdir(exist_ok=True)
        
        # Azure Speech Service é…ç½® - ä»ç¯å¢ƒå˜é‡åŠ è½½
        self.speech_key = os.getenv('AZURE_SPEECH_KEY')
        self.region = os.getenv('AZURE_SPEECH_REGION', 'switzerlandnorth')
        
        if self.generate_audio and not self.speech_key:
            print("âŒ è­¦å‘Š: æœªæ‰¾åˆ° AZURE_SPEECH_KEY ç¯å¢ƒå˜é‡ï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶")
            self.generate_audio = False
        
        # åˆå§‹åŒ–è¯­éŸ³åˆæˆå™¨
        if self.generate_audio and AZURE_SPEECH_AVAILABLE:
            try:
                self.tts = AzureSpeechSynthesizer(self.speech_key, self.region)
                print("âœ… Azureè¯­éŸ³åˆæˆå™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âŒ Azureè¯­éŸ³åˆæˆå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                self.generate_audio = False
        
        # åˆå§‹åŒ–promptå¢å¼ºå™¨
        self.prompt_enhancer = None
        if self.enhance_prompts and OPENAI_AVAILABLE:
            try:
                self.prompt_enhancer = PromptEnhancer()
                print("âœ… LLM promptå¢å¼ºå™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âŒ LLM promptå¢å¼ºå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                print(f"å°†è·³è¿‡promptå¢å¼ºåŠŸèƒ½")
                self.enhance_prompts = False
    
    def get_storyboard_files(self) -> List[Path]:
        """
        è·å–è¦å¤„ç†çš„æ•…äº‹æ¿æ–‡ä»¶åˆ—è¡¨
        
        Returns:
            list: æ•…äº‹æ¿æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        storyboard_files = []
        
        # å¤„ç†æ‰€æœ‰æ•…äº‹æ¿æ–‡ä»¶
        pattern = "*_storyboard.json"
        for storyboard_path in self.storyboard_dir.glob(pattern):
            storyboard_files.append(storyboard_path)
        
        if not storyboard_files:
            print(f"âŒ åœ¨ {self.storyboard_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½•æ•…äº‹æ¿æ–‡ä»¶")
        
        return storyboard_files
    
    def load_storyboard(self, shot_name: str) -> Dict[str, Any]:
        """
        åŠ è½½æŒ‡å®šåˆ†é›†çš„ storyboard.json æ–‡ä»¶
        
        Args:
            shot_name: åˆ†é›†åç§°ï¼Œå¦‚ 'shot_01'
            
        Returns:
            æ•…äº‹æ¿æ•°æ®å­—å…¸
        """
        storyboard_path = self.storyboard_dir / f"{shot_name}_storyboard.json"
        if not storyboard_path.exists():
            raise FileNotFoundError(f"Storyboard file not found: {storyboard_path}")
        
        with open(storyboard_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def translate_to_flux_prompt(self, chinese_desc: str) -> str:
        """
        å°†ä¸­æ–‡è§†è§‰æè¿°è½¬æ¢ä¸ºåŸºç¡€çš„Fluxé£æ ¼è‹±æ–‡promptï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
        
        Args:
            chinese_desc: ä¸­æ–‡è§†è§‰æè¿°
            
        Returns:
            è‹±æ–‡Fluxé£æ ¼prompt
        """
        # ç®€åŒ–çš„å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥ä½¿ç”¨ä¸­æ–‡æè¿°ç”ŸæˆåŸºç¡€prompt
        # è¿™ä¸ªæ–¹æ³•ä¸»è¦åœ¨LLMä¸å¯ç”¨æ—¶ä½œä¸ºæœ€åå¤‡ç”¨
        
        # åŸºæœ¬æ¸…ç†ï¼šç§»é™¤ä¸€äº›æ˜æ˜¾çš„ä¸­æ–‡æ ‡ç‚¹
        cleaned_desc = chinese_desc.replace("ï¼Œ", ", ").replace("ã€‚", ". ")
        
        # ç”ŸæˆåŸºç¡€çš„Fluxé£æ ¼prompt
        flux_style_prefix = "Cinematic shot, high quality, detailed rendering, "
        flux_style_suffix = ", dramatic lighting, masterpiece, best quality, ultra detailed, 8k resolution"
        
        # æ„å»ºæœ€ç»ˆçš„åŸºç¡€Flux prompt
        flux_prompt = f"{flux_style_prefix}{cleaned_desc}{flux_style_suffix}"
        
        return flux_prompt
    
    def generate_comfyui_prompts(self, enhanced_descriptions: List[Dict[str, str]], images_folder: Path) -> None:
        """
        ä»å¢å¼ºçš„æè¿°ä¸­æå–flux_promptå­—æ®µï¼Œç”ŸæˆComfyUIä¸“ç”¨çš„promptsæ•°ç»„
        
        Args:
            enhanced_descriptions: åŒ…å«flux_promptçš„æè¿°åˆ—è¡¨
            images_folder: å›¾åƒæ–‡ä»¶å¤¹è·¯å¾„
        """
        # æå–æ‰€æœ‰çš„flux_prompt
        comfyui_prompts = []
        for desc in enhanced_descriptions:
            flux_prompt = desc.get('flux_prompt', '')
            if flux_prompt:
                comfyui_prompts.append(flux_prompt)
        
        # ä¿å­˜ComfyUI promptsæ–‡ä»¶
        comfyui_prompts_path = images_folder / "comfyui_prompts.json"
        with open(comfyui_prompts_path, 'w', encoding='utf-8') as f:
            json.dump(comfyui_prompts, f, ensure_ascii=False, indent=2)
        
        print(f"å·²ç”ŸæˆComfyUI promptsæ–‡ä»¶: {comfyui_prompts_path}")
        print(f"åŒ…å« {len(comfyui_prompts)} ä¸ªå›¾åƒç”Ÿæˆprompt")
    
    def process_visual_descriptions(self, storyboard_data: Dict[str, Any]) -> List[Dict[str, str]]:
        """
        å¤„ç†è§†è§‰æè¿°ï¼Œç”ŸæˆåŒ…å«ä¸­æ–‡åŸæ–‡çš„æ•°ç»„ï¼ˆä¸ç”Ÿæˆåˆå§‹è‹±æ–‡promptï¼‰
        
        Args:
            storyboard_data: æ•…äº‹æ¿æ•°æ®
            
        Returns:
            è§†è§‰æè¿°åˆ—è¡¨
        """
        visual_descriptions = []
        
        # å¤„ç† preview_scenes
        for scene in storyboard_data.get("preview_scenes", []):
            if "visual_description" in scene:
                chinese_desc = scene["visual_description"]
                
                visual_descriptions.append({
                    "scene_number": scene.get("scene_number"),
                    "chinese_description": chinese_desc
                })
        
        # å¤„ç† main_scenes
        for scene in storyboard_data.get("main_scenes", []):
            if "visual_description" in scene:
                chinese_desc = scene["visual_description"]
                
                visual_descriptions.append({
                    "scene_number": scene.get("scene_number"),
                    "chinese_description": chinese_desc
                })
        
        return visual_descriptions
    
    def process_storylines(self, storyboard_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        å¤„ç†æ•…äº‹çº¿ï¼Œç”Ÿæˆæ•…äº‹çº¿æ•°ç»„
        
        Args:
            storyboard_data: æ•…äº‹æ¿æ•°æ®
            
        Returns:
            æ•…äº‹çº¿åˆ—è¡¨
        """
        storylines = []
        
        # å¤„ç† preview_scenes
        for scene in storyboard_data.get("preview_scenes", []):
            if "storyline" in scene:
                storylines.append({
                    "scene_number": scene.get("scene_number"),
                    "storyline": scene["storyline"]
                })
        
        # å¤„ç† main_scenes
        for scene in storyboard_data.get("main_scenes", []):
            if "storyline" in scene:
                storylines.append({
                    "scene_number": scene.get("scene_number"),
                    "storyline": scene["storyline"]
                })
        
        return storylines
    
    def generate_audio_files(self, storylines: List[Dict[str, Any]], shot_name: str) -> None:
        """
        ä¸ºstorylinesç”Ÿæˆé…éŸ³æ–‡ä»¶
        
        Args:
            storylines: æ•…äº‹çº¿åˆ—è¡¨
            shot_name: åˆ†é›†åç§°ï¼Œå¦‚ 'shot_01'
        """
        if not self.generate_audio or not AZURE_SPEECH_AVAILABLE:
            print("è·³è¿‡éŸ³é¢‘ç”Ÿæˆ")
            return
        
        print(f"å¼€å§‹ç”Ÿæˆ {shot_name} çš„é…éŸ³æ–‡ä»¶ï¼Œä½¿ç”¨éŸ³è‰²: {VoiceType.YUNXI.value}")
        
        # ç¡®ä¿éŸ³é¢‘ç›®å½•å­˜åœ¨
        audio_folder = self.assets_dir / shot_name / "audios"
        audio_folder.mkdir(parents=True, exist_ok=True)
        
        generated_count = 0
        skipped_count = 0
        
        for storyline in storylines:
            scene_number = storyline["scene_number"]
            text = storyline["storyline"]
            
            # ç”Ÿæˆç›®æ ‡éŸ³é¢‘æ–‡ä»¶åï¼ˆç¬¦åˆé¡¹ç›®å‘½åè§„åˆ™ï¼‰
            target_audio_filename = f"{shot_name}_{scene_number}.wav"
            target_audio_path = audio_folder / target_audio_filename
            
            # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            if target_audio_path.exists():
                print(f"â­ï¸  {shot_name} åœºæ™¯ {scene_number} éŸ³é¢‘å·²å­˜åœ¨ï¼Œè·³è¿‡ç”Ÿæˆ: {target_audio_filename}")
                skipped_count += 1
                continue
            
            try:
                print(f"ğŸµ æ­£åœ¨ç”Ÿæˆ {shot_name} åœºæ™¯ {scene_number} çš„é…éŸ³...")
                self.tts.synthesize_text(
                    text=text,
                    voice=VoiceType.YUNXI,
                    output_file=str(target_audio_path)
                )
                print(f"âœ… å·²ç”Ÿæˆ: {target_audio_filename}")
                generated_count += 1
                
            except Exception as e:
                print(f"âŒ {shot_name} åœºæ™¯ {scene_number} é…éŸ³ç”Ÿæˆå¤±è´¥: {e}")
        
        print(f"{shot_name} é…éŸ³ç”Ÿæˆå®Œæˆ! æ–°ç”Ÿæˆ: {generated_count} ä¸ª, è·³è¿‡: {skipped_count} ä¸ª")
        print(f"éŸ³é¢‘æ–‡ä»¶ä¿å­˜åœ¨: {audio_folder}")
    
    def remove_punctuation(self, text: str) -> str:
        """å»é™¤æ ‡ç‚¹ç¬¦å·"""
        # å®šä¹‰ä¸­è‹±æ–‡æ ‡ç‚¹ç¬¦å·æ¨¡å¼
        punctuation_pattern = r'[ï¼Œã€‚ï¼ï¼Ÿï¼šï¼›""''ã€Œã€ã€ã€ï¼ˆï¼‰ã€ã€‘ã€Šã€‹ã€ˆã€‰ã€,.!?:;"\'()\\[\\]{}<>/|~`@#$%^&*+=_-]'
        # å»é™¤æ ‡ç‚¹ç¬¦å·ï¼Œç”¨ç©ºæ ¼æ›¿æ¢
        clean_text = re.sub(punctuation_pattern, ' ', text)
        # å»é™¤å¤šä½™çš„ç©ºæ ¼
        clean_text = re.sub(r'\s+', ' ', clean_text).strip()
        return clean_text
    
    def split_into_chunks(self, text: str, max_chars_per_chunk: int = 15) -> List[str]:
        """å°†æ–‡æœ¬åˆ†å—ï¼Œæ¯å—ä¸è¶…è¿‡æŒ‡å®šå­—ç¬¦æ•°"""
        # å…ˆæŒ‰ç©ºæ ¼åˆ†å‰²æˆè¯
        words = text.split()
        chunks = []
        current_chunk = ""
        
        for word in words:
            # æ£€æŸ¥æ·»åŠ è¿™ä¸ªè¯åæ˜¯å¦ä¼šè¶…è¿‡é™åˆ¶
            test_chunk = current_chunk + (" " if current_chunk else "") + word
            
            if len(test_chunk) <= max_chars_per_chunk:
                # ä¸è¶…è¿‡é™åˆ¶ï¼Œæ·»åŠ è¿™ä¸ªè¯
                current_chunk = test_chunk
            else:
                # è¶…è¿‡é™åˆ¶ï¼Œä¿å­˜å½“å‰å—å¹¶å¼€å§‹æ–°å—
                if current_chunk.strip():
                    chunks.append(current_chunk.strip())
                current_chunk = word
        
        # æ·»åŠ æœ€åä¸€ä¸ªå—
        if current_chunk.strip():
            chunks.append(current_chunk.strip())
            
        return chunks
    
    def get_audio_duration(self, audio_path: str) -> float:
        """è·å–éŸ³é¢‘æ–‡ä»¶çš„æ—¶é•¿ï¼ˆç§’ï¼‰"""
        try:
            # é¦–é€‰æ–¹æ¡ˆï¼šä½¿ç”¨waveåº“è¯»å–WAVæ–‡ä»¶
            import wave
            with wave.open(audio_path, 'r') as wav_file:
                frames = wav_file.getnframes()
                rate = wav_file.getframerate()
                duration = frames / float(rate)
                return duration
        except Exception as e:
            print(f"è·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥ (wave): {e}")
            try:
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨moviepy
                from moviepy.editor import AudioFileClip
                audio_clip = AudioFileClip(audio_path)
                duration = audio_clip.duration
                audio_clip.close()
                return duration
            except ImportError:
                print("MoviePyæœªå®‰è£…ï¼Œä½¿ç”¨é»˜è®¤æ—¶é•¿")
            except Exception as e:
                print(f"è·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥ (moviepy): {e}")
        
        return 3.0  # é»˜è®¤3ç§’
    
    def _ensure_audio_files_exist(self, storylines: List[Dict[str, Any]], shot_name: str) -> bool:
        """
        ç¡®ä¿æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶éƒ½å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ç”Ÿæˆ
        
        Args:
            storylines: æ•…äº‹çº¿åˆ—è¡¨
            shot_name: åˆ†é›†åç§°ï¼Œå¦‚ 'shot_01'
            
        Returns:
            bool: æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶æ˜¯å¦æœ€ç»ˆéƒ½å­˜åœ¨
        """
        print(f"ğŸ” æ£€æŸ¥ {shot_name} çš„éŸ³é¢‘æ–‡ä»¶çŠ¶æ€...")
        
        # éŸ³é¢‘æ–‡ä»¶ç›®å½•
        audio_folder = self.assets_dir / shot_name / "audios"
        audio_folder.mkdir(parents=True, exist_ok=True)
        
        # æ£€æŸ¥æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        missing_audio_files = []
        expected_audio_files = []
        
        for storyline in storylines:
            scene_number = storyline["scene_number"]
            audio_filename = f"{shot_name}_{scene_number}.wav"
            audio_path = audio_folder / audio_filename
            expected_audio_files.append(audio_filename)
            
            if not audio_path.exists():
                missing_audio_files.append(audio_filename)
        
        if not missing_audio_files:
            print(f"âœ… æ‰€æœ‰ {len(expected_audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶éƒ½å·²å­˜åœ¨")
            return True
        
        # æœ‰ç¼ºå¤±çš„éŸ³é¢‘æ–‡ä»¶ï¼Œå¼€å§‹ç”Ÿæˆ
        print(f"âŒ å‘ç° {len(missing_audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶ç¼ºå¤±:")
        for missing_file in missing_audio_files:
            print(f"   - {missing_file}")
        
        if not self.tts:
            print(f"âŒ Azureè¯­éŸ³åˆæˆå™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•ç”ŸæˆéŸ³é¢‘æ–‡ä»¶")
            return False
        
        print(f"ğŸµ å¼€å§‹ç”Ÿæˆç¼ºå¤±çš„éŸ³é¢‘æ–‡ä»¶...")
        
        try:
            # ç”ŸæˆéŸ³é¢‘æ–‡ä»¶
            self.generate_audio_files(storylines, shot_name)
            print(f"âœ… éŸ³é¢‘ç”Ÿæˆå®Œæˆ")
            
            # éªŒè¯æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶æ˜¯å¦éƒ½å·²ç”Ÿæˆ
            print(f"ğŸ” éªŒè¯éŸ³é¢‘æ–‡ä»¶ç”Ÿæˆç»“æœ...")
            final_missing_files = []
            for storyline in storylines:
                scene_number = storyline["scene_number"]
                audio_filename = f"{shot_name}_{scene_number}.wav"
                audio_path = audio_folder / audio_filename
                if not audio_path.exists():
                    final_missing_files.append(audio_filename)
            
            if final_missing_files:
                print(f"âŒ ä»æœ‰ {len(final_missing_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶ç”Ÿæˆå¤±è´¥:")
                for missing_file in final_missing_files:
                    print(f"   - {missing_file}")
                return False
            else:
                print(f"âœ… æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶å·²æˆåŠŸç”Ÿæˆå¹¶éªŒè¯å®Œæˆ")
                return True
                
        except Exception as e:
            print(f"âŒ éŸ³é¢‘ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def generate_complete_rst_file(self, storylines: List[Dict[str, Any]], shot_name: str) -> List[Dict]:
        """
        æ ¹æ®storylinesç”Ÿæˆå®Œæ•´çš„RSTå­—å¹•æ–‡ä»¶
        
        Args:
            storylines: æ•…äº‹çº¿åˆ—è¡¨
            shot_name: åˆ†é›†åç§°ï¼Œå¦‚ 'shot_01'
            
        Returns:
            list: åŒ…å«æ‰€æœ‰ç‰‡æ®µæ—¶é—´ä¿¡æ¯çš„åˆ—è¡¨
        """
        print(f"ğŸ“ å¼€å§‹ç”Ÿæˆ {shot_name} çš„RSTå­—å¹•æ–‡ä»¶...")
        
        # éŸ³é¢‘æ–‡ä»¶ç›®å½•
        audio_folder = self.assets_dir / shot_name / "audios"
        
        # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶çŠ¶æ€ï¼ˆåªåšæœ€ç»ˆç¡®è®¤ï¼Œä¸ç”Ÿæˆï¼‰
        missing_audio_files = []
        for storyline in storylines:
            scene_number = storyline["scene_number"]
            audio_filename = f"{shot_name}_{scene_number}.wav"
            audio_path = audio_folder / audio_filename
            if not audio_path.exists():
                missing_audio_files.append(audio_filename)
        
        if missing_audio_files:
            print(f"âš ï¸  å‘ç° {len(missing_audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶ä»ç„¶ç¼ºå¤±ï¼Œå°†ä½¿ç”¨é»˜è®¤æ—¶é•¿ 3.0 ç§’")
        else:
            print(f"âœ… æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶å·²å°±ç»ªï¼Œä½¿ç”¨å®é™…éŸ³é¢‘æ—¶é•¿")
        
        all_segments = []
        current_start_time = 0.0
        
        # å¤„ç†æ¯ä¸ªåœºæ™¯çš„storyline
        for i, storyline in enumerate(storylines, 1):
            scene_number = storyline["scene_number"]
            storyline_text = storyline["storyline"]
            
            # æ„å»ºå¯¹åº”çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            audio_filename = f"{shot_name}_{scene_number}.wav"
            audio_path = audio_folder / audio_filename
            
            # è·å–éŸ³é¢‘æ—¶é•¿
            if audio_path.exists():
                scene_duration = self.get_audio_duration(str(audio_path))
            else:
                # ä½¿ç”¨é»˜è®¤æ—¶é•¿ï¼ˆé”™è¯¯ä¿¡æ¯å·²åœ¨ä¸Šé¢æ˜¾ç¤ºè¿‡ï¼‰
                scene_duration = 3.0
            
            # é¢„å¤„ç†å­—å¹•æ–‡æœ¬
            clean_text = self.remove_punctuation(storyline_text)
            
            # æ–‡æœ¬åˆ†å—
            chunks = self.split_into_chunks(clean_text)
            
            # å¦‚æœæ²¡æœ‰åˆ†å—ï¼Œä½¿ç”¨åŸæ–‡
            if not chunks:
                chunks = [clean_text or storyline_text]
            
            # è®¡ç®—æ¯ä¸ªå—çš„æ—¶é—´åˆ†é…
            chunk_duration = scene_duration / len(chunks) if chunks else scene_duration
            
            # ä¸ºæ¯ä¸ªå—åˆ›å»ºæ—¶é—´æ®µ
            for j, chunk in enumerate(chunks):
                segment_start = current_start_time + j * chunk_duration
                segment_end = current_start_time + (j + 1) * chunk_duration
                
                segment_info = {
                    'scene': scene_number,
                    'chunk': j + 1,
                    'text': chunk,
                    'start_time': segment_start,
                    'end_time': segment_end,
                    'duration': chunk_duration
                }
                all_segments.append(segment_info)
                print(f"  {shot_name} åœºæ™¯{scene_number}_ç‰‡æ®µ{j+1}: {segment_start:.2f}s-{segment_end:.2f}s | {chunk}")
            
            # æ›´æ–°å½“å‰å¼€å§‹æ—¶é—´
            current_start_time += scene_duration
        
        # ç”Ÿæˆå®Œæ•´çš„RSTå†…å®¹
        total_duration = current_start_time
        rst_content = self.generate_complete_rst_content(all_segments, total_duration)
        
        # ä¿å­˜RSTæ–‡ä»¶åˆ°subtitlesç›®å½•
        subtitles_folder = self.assets_dir / shot_name / "subtitles"
        subtitles_folder.mkdir(parents=True, exist_ok=True)
        final_rst_path = subtitles_folder / f"{shot_name}.rst"
        with open(final_rst_path, 'w', encoding='utf-8') as f:
            f.write(rst_content)
        
        print(f"{shot_name} å®Œæ•´RSTæ–‡ä»¶å·²ä¿å­˜åˆ°: {final_rst_path}")
        print(f"æ€»æ—¶é•¿: {total_duration:.2f}s, æ€»ç‰‡æ®µæ•°: {len(all_segments)}")
        
        return all_segments
    
    def generate_complete_rst_content(self, segments: List[Dict], total_duration: float) -> str:
        """
        ç”Ÿæˆå®Œæ•´çš„RSTå†…å®¹
        
        Args:
            segments: æ‰€æœ‰å­—å¹•ç‰‡æ®µä¿¡æ¯
            total_duration: è§†é¢‘æ€»æ—¶é•¿
        
        Returns:
            str: RSTæ ¼å¼çš„å†…å®¹
        """
        rst_content = f"""å®Œæ•´è§†é¢‘å­—å¹•æ–‡ä»¶
==================

:åˆ›å»ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
:æ€»æ—¶é•¿: {total_duration:.2f}ç§’
:ç‰‡æ®µæ•°é‡: {len(segments)}
:å­—ä½“: å¾®è½¯é›…é»‘
:å­—ä½“å¤§å°: 70px
:æè¾¹å®½åº¦: 3px

å­—å¹•å†…å®¹
--------

"""
        
        for segment in segments:
            rst_content += f"""
.. subtitle:: åœºæ™¯{segment['scene']:02d}_ç‰‡æ®µ{segment['chunk']:02d}
   :start_time: {segment['start_time']:.2f}
   :end_time: {segment['end_time']:.2f}
   :duration: {segment['duration']:.2f}
   :text: {segment['text']}

"""
        
        rst_content += f"""

æ ·å¼é…ç½®
--------

.. style_config::
   :font_family: C:/Windows/Fonts/msyh.ttc
   :font_size: 70
   :font_color: #FFFFFF
   :stroke_width: 3
   :stroke_color: #000000
   :position: bottom_third

ç”Ÿæˆä¿¡æ¯
--------

:ç”Ÿæˆå·¥å…·: storyboard_processor.py
:åŸºäºå†…å®¹: storyline
:åˆ†å—è§„åˆ™: æœ€å¤§15å­—ç¬¦æ¯å—
:æ—¶é—´åˆ†é…: åŸºäºéŸ³é¢‘æ–‡ä»¶æ—¶é•¿å‡åŒ€åˆ†é…

"""
        
        return rst_content
    
    def process(self, shot_name: str = None) -> None:
        """
        æ‰§è¡Œå®Œæ•´çš„å¤„ç†æµç¨‹
        
        Args:
            shot_name: ç‰¹å®šåˆ†é›†åç§°ï¼Œå¦‚ 'shot_01'ã€‚å¦‚æœä¸ºNoneï¼Œåˆ™å¤„ç†æ‰€æœ‰åˆ†é›†
        """
        if shot_name:
            # å¤„ç†ç‰¹å®šåˆ†é›†
            self.process_single_shot(shot_name)
        else:
            # æ‰¹é‡å¤„ç†æ‰€æœ‰åˆ†é›†
            storyboard_files = self.get_storyboard_files()
            if not storyboard_files:
                print("æœªæ‰¾åˆ°ä»»ä½•æ•…äº‹æ¿æ–‡ä»¶")
                return
            
            print(f"å‘ç° {len(storyboard_files)} ä¸ªæ•…äº‹æ¿æ–‡ä»¶ï¼Œå¼€å§‹æ‰¹é‡å¤„ç†...")
            for storyboard_file in storyboard_files:
                shot_name = storyboard_file.stem.replace('_storyboard', '')
                self.process_single_shot(shot_name)
                print("-" * 50)
    
    def process_single_shot(self, shot_name: str) -> None:
        """
        å¤„ç†å•ä¸ªåˆ†é›†çš„æ•…äº‹æ¿
        
        Args:
            shot_name: åˆ†é›†åç§°ï¼Œå¦‚ 'shot_01'
        """
        print(f"æ­£åœ¨å¤„ç†æ•…äº‹æ¿: {shot_name}")
        
        # åŠ è½½æ•…äº‹æ¿æ•°æ®
        storyboard_data = self.load_storyboard(shot_name)
        
        # å¤„ç†è§†è§‰æè¿°ï¼ˆåªæå–ä¸­æ–‡æè¿°ï¼‰
        visual_descriptions = self.process_visual_descriptions(storyboard_data)
        images_folder = self.assets_dir / shot_name / "images"
        images_folder.mkdir(parents=True, exist_ok=True)
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨å¢å¼ºåçš„promptsæ–‡ä»¶
        flux_prompts_path = images_folder / "flux_prompts.json"
        
        if flux_prompts_path.exists() and not self.enhance_prompts:
            # å¦‚æœæ–‡ä»¶å­˜åœ¨ä½†ç¦ç”¨äº†å¢å¼ºåŠŸèƒ½ï¼Œç›´æ¥åŠ è½½ç°æœ‰æ–‡ä»¶
            print(f"ğŸ“„ å‘ç°ç°æœ‰çš„flux promptsæ–‡ä»¶: {flux_prompts_path}")
            with open(flux_prompts_path, 'r', encoding='utf-8') as f:
                enhanced_descriptions = json.load(f)
            print(f"å·²åŠ è½½ç°æœ‰çš„fluxå›¾åƒç”Ÿæˆprompts")
            
            # æ£€æŸ¥å¹¶ç”ŸæˆComfyUI promptsæ–‡ä»¶
            comfyui_prompts_path = images_folder / "comfyui_prompts.json"
            if not comfyui_prompts_path.exists():
                self.generate_comfyui_prompts(enhanced_descriptions, images_folder)
            
        elif flux_prompts_path.exists() and self.enhance_prompts:
            # å¦‚æœæ–‡ä»¶å­˜åœ¨ä¸”å¯ç”¨äº†å¢å¼ºåŠŸèƒ½ï¼Œè¯¢é—®æ˜¯å¦è·³è¿‡
            print(f"ğŸ“„ å‘ç°ç°æœ‰çš„flux promptsæ–‡ä»¶: {flux_prompts_path}")
            print(f"ğŸ”„ è·³è¿‡LLMè°ƒç”¨ï¼Œä½¿ç”¨ç°æœ‰æ–‡ä»¶")
            with open(flux_prompts_path, 'r', encoding='utf-8') as f:
                enhanced_descriptions = json.load(f)
            print(f"å·²åŠ è½½ç°æœ‰çš„fluxå›¾åƒç”Ÿæˆprompts")
            
            # æ£€æŸ¥å¹¶ç”ŸæˆComfyUI promptsæ–‡ä»¶
            comfyui_prompts_path = images_folder / "comfyui_prompts.json"
            if not comfyui_prompts_path.exists():
                self.generate_comfyui_prompts(enhanced_descriptions, images_folder)
            
        else:
            # éœ€è¦ç”Ÿæˆæ–°çš„prompts
            if self.enhance_prompts and self.prompt_enhancer:
                # ä½¿ç”¨LLMç›´æ¥ç”Ÿæˆprompts
                enhanced_descriptions = self.prompt_enhancer.generate_flux_prompts_batch(visual_descriptions)
                
                # ä¿å­˜ç”Ÿæˆåçš„prompts
                with open(flux_prompts_path, 'w', encoding='utf-8') as f:
                    json.dump(enhanced_descriptions, f, ensure_ascii=False, indent=2)
                print(f"å·²ä¿å­˜LLMç”Ÿæˆçš„å›¾åƒprompts: {flux_prompts_path}")
                
                # ç”ŸæˆComfyUIä¸“ç”¨çš„promptsæ–‡ä»¶
                self.generate_comfyui_prompts(enhanced_descriptions, images_folder)
                
            else:
                # å¦‚æœç¦ç”¨äº†å¢å¼ºæˆ–åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•
                print("âš ï¸  LLMç”Ÿæˆè¢«ç¦ç”¨æˆ–åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨ç¿»è¯‘æ–¹æ³•")
                enhanced_descriptions = []
                for desc in visual_descriptions:
                    chinese_desc = desc.get('chinese_description', '')
                    fallback_prompt = self.translate_to_flux_prompt(chinese_desc)
                    
                    enhanced_desc = desc.copy()
                    enhanced_desc['flux_prompt'] = fallback_prompt
                    enhanced_descriptions.append(enhanced_desc)
                
                # ä¿å­˜å¤‡ç”¨promptsåˆ°åŸºç¡€æ–‡ä»¶
                basic_prompts_path = images_folder / "basic_flux_prompts.json"
                with open(basic_prompts_path, 'w', encoding='utf-8') as f:
                    json.dump(enhanced_descriptions, f, ensure_ascii=False, indent=2)
                print(f"å·²ä¿å­˜åŸºç¡€å›¾åƒç”Ÿæˆprompts: {basic_prompts_path}")
                
                # ç”ŸæˆComfyUIä¸“ç”¨çš„promptsæ–‡ä»¶
                self.generate_comfyui_prompts(enhanced_descriptions, images_folder)
        
        # æ›´æ–°visual_descriptionsä¸ºæœ€ç»ˆç‰ˆæœ¬
        visual_descriptions = enhanced_descriptions
        
        # å¤„ç†æ•…äº‹çº¿å¹¶ä¿å­˜åˆ°subtitlesç›®å½•
        storylines = self.process_storylines(storyboard_data)
        subtitles_folder = self.assets_dir / shot_name / "subtitles"
        subtitles_folder.mkdir(parents=True, exist_ok=True)
        storyline_path = subtitles_folder / f"{shot_name}_storylines.json"
        with open(storyline_path, 'w', encoding='utf-8') as f:
            json.dump(storylines, f, ensure_ascii=False, indent=2)
        print(f"å·²ä¿å­˜æ•…äº‹çº¿åˆ°: {storyline_path}")
        
        # æ­¥éª¤1ï¼šæ£€æŸ¥å¹¶ç”ŸæˆéŸ³é¢‘æ–‡ä»¶
        if self.generate_audio:
            self._ensure_audio_files_exist(storylines, shot_name)
        
        # æ­¥éª¤2ï¼šç”Ÿæˆå­—å¹•RSTæ–‡ä»¶ï¼ˆæ­¤æ—¶éŸ³é¢‘æ–‡ä»¶åº”è¯¥å·²å®Œæ•´ï¼‰
        subtitle_segments = self.generate_complete_rst_file(storylines, shot_name)
        print(f"âœ… å­—å¹•æ–‡ä»¶ç”Ÿæˆå®Œæˆ: {len(subtitle_segments)} ä¸ªç‰‡æ®µ")
        
        print(f"{shot_name} å¤„ç†å®Œæˆ!")
        print(f"å›¾åƒpromptså·²ä¿å­˜åˆ°: {images_folder}")
        print(f"å­—å¹•æ–‡ä»¶å·²ä¿å­˜åˆ°: {subtitles_folder}")
        print(f"éŸ³é¢‘æ–‡ä»¶ç›®å½•: {self.assets_dir / shot_name / 'audios'}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å¤„ç†æ•…äº‹æ¿æ–‡ä»¶ï¼Œç”Ÿæˆè§†è§‰æè¿°promptå’Œæ•…äº‹çº¿')
    parser.add_argument('--shot', help='æŒ‡å®šå¤„ç†çš„åˆ†é›†ï¼Œå¦‚ shot_01ã€‚å¦‚æœä¸æŒ‡å®šï¼Œåˆ™æ‰¹é‡å¤„ç†æ‰€æœ‰åˆ†é›†')
    parser.add_argument('--no-audio', action='store_true', 
                       help='è·³è¿‡é…éŸ³æ–‡ä»¶ç”Ÿæˆï¼ˆé»˜è®¤ä¼šè‡ªåŠ¨ç”ŸæˆéŸ³é¢‘ï¼‰')
    parser.add_argument('--no-enhance', action='store_true',
                       help='è·³è¿‡LLM promptå¢å¼ºï¼ˆé»˜è®¤ä¼šä½¿ç”¨LLMå¢å¼ºå›¾åƒpromptsï¼‰')
    parser.add_argument('--assets-dir', default='assets', 
                       help='èµ„æºç›®å½•è·¯å¾„ï¼ˆé»˜è®¤ï¼šassetsï¼‰')
    
    args = parser.parse_args()
    
    # é»˜è®¤ç”ŸæˆéŸ³é¢‘ï¼Œé™¤éæŒ‡å®š --no-audio
    generate_audio = not args.no_audio
    # é»˜è®¤å¢å¼ºpromptï¼Œé™¤éæŒ‡å®š --no-enhance
    enhance_prompts = not args.no_enhance
    
    try:
        processor = StoryboardProcessor(
            shot_name=args.shot, 
            generate_audio=generate_audio, 
            storyboard_dir="storyboard",
            assets_dir=args.assets_dir,
            enhance_prompts=enhance_prompts
        )
        processor.process(args.shot)
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
